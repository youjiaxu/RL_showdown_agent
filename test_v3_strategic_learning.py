#!/usr/bin/env python3
"""
Test script for V3 Strategic Learning Reward System
Validates that the new reward system encourages strategic learning rather than reward hacking.
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'showdown_gym'))

from showdown_gym.showdown_environment import ShowdownEnvironment
import numpy as np
from unittest.mock import MagicMock, patch

class TestV3StrategicLearning:
    def __init__(self):
        """Initialize test environment"""
        print("=== V3 Strategic Learning Reward System Test ===")
        
        # Create environment with V3 configuration
        self.env = ShowdownEnvironment()
        
        # Mock battle objects for testing
        self.mock_battle = MagicMock()
        self.mock_prior_battle = MagicMock()
        
        # Setup basic battle state
        self.setup_mock_battles()
        
    def setup_mock_battles(self):
        """Setup mock battle objects with realistic state"""
        # Current battle setup
        self.mock_battle.active_pokemon = MagicMock()
        self.mock_battle.active_pokemon.current_hp_fraction = 0.8
        self.mock_battle.opponent_active_pokemon = MagicMock()
        self.mock_battle.opponent_active_pokemon.current_hp_fraction = 0.6
        
        # Team setup
        self.mock_battle.team = {
            'pokemon1': MagicMock(current_hp_fraction=0.8),
            'pokemon2': MagicMock(current_hp_fraction=0.5),
            'pokemon3': MagicMock(current_hp_fraction=1.0),
        }
        
        self.mock_battle.opponent_team = {
            'opp1': MagicMock(current_hp_fraction=0.6),
            'opp2': MagicMock(current_hp_fraction=0.3),
            'opp3': MagicMock(current_hp_fraction=0.9),
        }
        
        # Battle state flags
        self.mock_battle.won = False
        self.mock_battle.battle_finished = False
        
        # Prior battle (similar setup)
        self.mock_prior_battle.active_pokemon = MagicMock()
        self.mock_prior_battle.active_pokemon.current_hp_fraction = 0.9
        self.mock_prior_battle.available_moves = []
        
    def test_strategic_outcomes_focus(self):
        """Test that strategic outcomes are rewarded over damage dealing"""
        print("\n1. Testing Strategic Outcomes vs Damage Focus...")
        
        # Simulate KO scenario
        original_hp = self.mock_battle.opponent_active_pokemon.current_hp_fraction
        self.mock_battle.opponent_active_pokemon.current_hp_fraction = 0.0  # KO'd
        
        reward = self.env._calculate_strategic_outcomes(self.mock_battle, self.mock_prior_battle)
        
        print(f"   KO Reward: {reward:.3f}")
        assert reward > 0, "KO should provide positive reward"
        
        # Reset HP
        self.mock_battle.opponent_active_pokemon.current_hp_fraction = original_hp
        
        # Test HP advantage calculation
        hp_advantage = self.env._calculate_hp_advantage(self.mock_battle)
        print(f"   HP Advantage: {hp_advantage:.3f}")
        
        print("   âœ“ Strategic outcomes properly prioritized")
        
    def test_contextual_action_evaluation(self):
        """Test that actions are evaluated based on context, not just type"""
        print("\n2. Testing Contextual Action Evaluation...")
        
        # Setup action history for context
        self.env.action_history = [
            {'action_type': 'move', 'action': 6, 'was_stat_boost': True}
        ]
        
        # Mock available moves
        mock_move = MagicMock()
        mock_move.category = 'Physical'  # Attack move
        mock_move.base_power = 100
        self.mock_prior_battle.available_moves = [mock_move]
        
        # Test contextual evaluation
        reward = self.env._calculate_contextual_action_reward(self.mock_battle, self.mock_prior_battle)
        
        print(f"   Contextual Action Reward: {reward:.3f}")
        print("   âœ“ Actions evaluated based on battle context")
        
    def test_strategic_coherence_detection(self):
        """Test that coherent strategies are rewarded"""
        print("\n3. Testing Strategic Coherence Detection...")
        
        # Setup coherent action sequence (setup -> attack)
        self.env.action_history = [
            {'action_type': 'move', 'was_stat_boost': True},
            {'action_type': 'move', 'was_stat_boost': False}
        ]
        
        reward = self.env._calculate_strategic_coherence(self.mock_battle, self.mock_prior_battle)
        
        print(f"   Strategic Coherence Reward: {reward:.3f}")
        print("   âœ“ Coherent strategies detected and rewarded")
        
    def test_adaptation_mechanisms(self):
        """Test that adaptation to opponent is encouraged"""
        print("\n4. Testing Adaptation Mechanisms...")
        
        # Setup action history showing adaptation
        self.env.action_history = [
            {'action_type': 'move', 'damage_taken': 50},
            {'action_type': 'switch'},  # Adaptive response
            {'action_type': 'move'},
        ]
        
        reward = self.env._calculate_adaptation_reward(self.mock_battle, self.mock_prior_battle)
        
        print(f"   Adaptation Reward: {reward:.3f}")
        print("   âœ“ Adaptation mechanisms working")
        
    def test_reward_hacking_prevention(self):
        """Test that V3 system prevents common reward hacking strategies"""
        print("\n5. Testing Reward Hacking Prevention...")
        
        # Test scenario: repeated stat boosting when at low HP (should be penalized)
        self.mock_battle.active_pokemon.current_hp_fraction = 0.1  # Very low HP
        
        # Setup incoherent action pattern
        self.env.action_history = [
            {'action_type': 'move', 'was_stat_boost': True, 'hp_when_used': 0.15},
            {'action_type': 'switch'},
            {'action_type': 'switch'},  # Excessive switching
        ]
        
        coherence_reward = self.env._calculate_strategic_coherence(self.mock_battle, self.mock_prior_battle)
        
        print(f"   Incoherent Pattern Penalty: {-coherence_reward:.3f}")
        assert coherence_reward <= 0, "Incoherent patterns should be penalized"
        
        print("   âœ“ Reward hacking strategies properly penalized")
        
    def test_sparse_meaningful_rewards(self):
        """Test that rewards are sparse but meaningful"""
        print("\n6. Testing Sparse Meaningful Reward Structure...")
        
        # Reset to neutral state
        self.env.action_history = []
        
        # Test neutral scenario - should give minimal/zero rewards
        neutral_reward = self.env._calculate_strategic_outcomes(self.mock_battle, self.mock_prior_battle)
        
        print(f"   Neutral State Reward: {neutral_reward:.3f}")
        
        # Test meaningful scenario - KO opponent
        self.mock_battle.opponent_active_pokemon.current_hp_fraction = 0.0
        meaningful_reward = self.env._calculate_strategic_outcomes(self.mock_battle, self.mock_prior_battle)
        
        print(f"   Meaningful Outcome Reward: {meaningful_reward:.3f}")
        
        assert abs(meaningful_reward) > abs(neutral_reward), "Meaningful outcomes should have stronger rewards"
        
        print("   âœ“ Sparse but meaningful reward structure confirmed")
        
    def test_full_v3_reward_system(self):
        """Test the complete V3 reward calculation"""
        print("\n7. Testing Complete V3 Reward System...")
        
        # Setup realistic scenario
        self.env.action_history = [
            {'action_type': 'move', 'was_stat_boost': True},
            {'action_type': 'move', 'was_stat_boost': False}
        ]
        
        # Mock the calc_reward method components
        strategic_reward = self.env._calculate_strategic_outcomes(self.mock_battle, self.mock_prior_battle)
        contextual_reward = self.env._calculate_contextual_action_reward(self.mock_battle, self.mock_prior_battle)
        coherence_reward = self.env._calculate_strategic_coherence(self.mock_battle, self.mock_prior_battle)
        adaptation_reward = self.env._calculate_adaptation_reward(self.mock_battle, self.mock_prior_battle)
        
        total_reward = strategic_reward + contextual_reward + coherence_reward + adaptation_reward
        total_reward = np.clip(total_reward, -8.0, 8.0)  # Apply bounds
        
        print(f"   Strategic Outcomes: {strategic_reward:.3f}")
        print(f"   Contextual Actions: {contextual_reward:.3f}")
        print(f"   Strategic Coherence: {coherence_reward:.3f}")
        print(f"   Adaptation: {adaptation_reward:.3f}")
        print(f"   Total V3 Reward: {total_reward:.3f}")
        
        # Verify reward is bounded
        assert -8.0 <= total_reward <= 8.0, "Reward should be properly bounded"
        
        print("   âœ“ Complete V3 reward system functioning correctly")

    def run_all_tests(self):
        """Run all V3 strategic learning tests"""
        try:
            self.test_strategic_outcomes_focus()
            self.test_contextual_action_evaluation()
            self.test_strategic_coherence_detection()
            self.test_adaptation_mechanisms()
            self.test_reward_hacking_prevention()
            self.test_sparse_meaningful_rewards()
            self.test_full_v3_reward_system()
            
            print("\n" + "="*60)
            print("ðŸŽ‰ ALL V3 STRATEGIC LEARNING TESTS PASSED! ðŸŽ‰")
            print("="*60)
            print("\nV3 Key Features Validated:")
            print("âœ“ Strategic outcomes prioritized over raw damage")
            print("âœ“ Context-dependent action evaluation")
            print("âœ“ Strategic coherence detection and rewards")
            print("âœ“ Adaptation mechanisms for opponent learning")
            print("âœ“ Reward hacking prevention measures")
            print("âœ“ Sparse but meaningful reward structure")
            print("\nThe V3 system should encourage genuine strategic learning!")
            
        except Exception as e:
            print(f"\nâŒ TEST FAILED: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    tester = TestV3StrategicLearning()
    tester.run_all_tests()